---
title: "combine_data_youtube_countries"
format: html
---

<br>

```{r}
library(tidyverse)
library(dplyr)
getwd()
DEvideos <- read_csv("raw_data_from_kaggle/DEvideos.csv")
FRvideos <- read_csv("raw_data_from_kaggle/FRvideos.csv")
JPvideos <- read_csv("raw_data_from_kaggle/JPvideos.csv")
MXvideos <- read_csv("raw_data_from_kaggle/MXvideos.csv")
USvideos <- read_csv("raw_data_from_kaggle/USvideos.csv")
str(DEvideos)
str(FRvideos)
str(JPvideos)
str(MXvideos)
str(USvideos)
```

<br>
```{r}

# Add a 'country' column and standardize data types for each data frame
DEvideos <- DEvideos %>%
  mutate(
    country = "DE",
    across(c(comments_disabled, ratings_disabled, video_error_or_removed), as.character)
  )

FRvideos <- FRvideos %>%
  mutate(
    country = "FR",
    across(c(comments_disabled, ratings_disabled, video_error_or_removed), as.character)
  )

JPvideos <- JPvideos %>%
  mutate(
    country = "JP",
    across(c(comments_disabled, ratings_disabled, video_error_or_removed), as.character)
  )

MXvideos <- MXvideos %>%
  mutate(
    country = "MX",
    across(c(comments_disabled, ratings_disabled, video_error_or_removed), as.character)
  )

USvideos <- USvideos %>%
  mutate(
    country = "US",
    across(c(comments_disabled, ratings_disabled, video_error_or_removed), as.character)
  )

# Combine all data frames into a single one
all_videos <- bind_rows(DEvideos, FRvideos, JPvideos, MXvideos, USvideos)

# Check the structure of the new, combined data frame
str(all_videos)
```
<br>

```{r}
# Convert the trending_date column to a proper date format
all_videos <- all_videos %>%
  mutate(trending_date = as.Date(trending_date, format = "%y.%d.%m"))

# Check the structure again to confirm the change
str(all_videos$trending_date)

# Find the earliest and latest trending dates
earliest_date <- min(all_videos$trending_date)
latest_date <- max(all_videos$trending_date)
earliest_date
latest_date
# wordcloud nicht vergessen
```
<br>

<br>

```{r}


# 1. Separate the tags into individual rows
# The separate_rows() function is perfect for this
tags_per_day <- all_videos %>%
  separate_rows(tags, sep = "\\|")
  

View(tags_per_day)
str(tags_per_day)
# 2. Group by date and tag, then count occurrences
trending_tags <- tags_per_day %>%
  group_by(trending_date, tags) %>%
  count(sort = TRUE) %>%
  ungroup()
# View(trending_tags)

# 3. View the top trending tags
# You can filter for a specific date or just look at the top overall
head(trending_tags, 20)
unique_tags_df <- trending_tags %>%
  distinct(tags)
# View(unique_tags_df)

# the single most-searched tag across all countries and dates
most_searched_tag <- tags_per_day %>%
  group_by(tags) %>%
  count(sort = TRUE) %>%
  ungroup()
  
View(most_searched_tag)

# Finding the Most Searched Tag for Each Country
most_searched_tags_by_country <- tags_per_day %>%
  group_by(country, tags) %>%
  count(name = "total_appearances") %>%
  slice_max(order_by = total_appearances, n = 1) %>%
  ungroup() %>%
  arrange(country)

View(most_searched_tags_by_country)
```
<br>

<br>

```{r}
# Group by country and category_id and count the number of videos
category_counts <- all_videos %>%
  group_by(country, category_id) %>%
  count() %>%
  ungroup()

# View the result
head(category_counts)
View(category_counts)



# Create the grouped bar chart
ggplot(category_counts, aes(x = factor(category_id), y = n, fill = country)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Count of Trending Videos by Category and Country",
    x = "Category ID",
    y = "Number of Trending Videos",
    fill = "Country"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```
<br>


<br>
```{r}

# Filter for the three keywords and create a new 'keyword' column
relevant_videos <- tags_per_day %>%
  filter(grepl("iphone|tesla|rolex", tags, ignore.case = TRUE)) %>%
  mutate(keyword = case_when(
    grepl("iphone", tags, ignore.case = TRUE) ~ "iPhone",
    grepl("tesla", tags, ignore.case = TRUE) ~ "Tesla",
    grepl("rolex", tags, ignore.case = TRUE) ~ "Rolex",
    TRUE ~ "Other" # This case should ideally not be triggered after filtering
  ))

# Let's check the structure and a few rows
str(relevant_videos)
head(relevant_videos)

<br>
```
<br>

```{r}

# Aggregate the data by date, country, and keyword
aggregated_youtube_data <- relevant_videos %>%
  group_by(trending_date, country, keyword) %>%
  summarise(
    total_views = sum(views, na.rm = TRUE),
    total_likes = sum(likes, na.rm = TRUE),
    total_comments = sum(comment_count, na.rm = TRUE),
    total_dislikes = sum(dislikes, na.rm = TRUE), # Remember the warning about missing US data
    video_count = n()
  ) %>%
  ungroup()

# Check the new, aggregated dataframe
View(aggregated_youtube_data)
```

<br>

```{r}
# Calculate the engagement ratios
aggregated_youtube_data_final <- aggregated_youtube_data %>%
  mutate(
    # ratios calculations
    like_dislike_ratio = total_likes / (total_likes + total_dislikes), 
    comments_views_ratio = total_comments / total_views,
    likes_views_ratio = total_likes / total_views,
    dislikes_views_ratio = total_dislikes / total_views
  ) %>%
  # Select and rename columns for a clean final table
  # Select: choosing which columns to keep and in what order
  select(
    trending_date, 
    country, 
    keyword, 
    total_views, 
    total_likes,
    total_dislikes,
    total_comments, 
    video_count, 
    like_dislike_ratio,
    comments_views_ratio,
    likes_views_ratio,
    dislikes_views_ratio
  )

# View the final dataframe, ready for merging
View(aggregated_youtube_data_final)
```

<br>

```{r}
#  Calculate the Mean of Proportions and Ratios for each Keyword in each Country
mean_ratios_by_country_keyword <- aggregated_youtube_data_final %>%
  group_by(country, keyword) %>%
  summarise(
    avg_like_dislike_ratio = mean(like_dislike_ratio, na.rm = TRUE),
    avg_comments_views_ratio = mean(comments_views_ratio, na.rm = TRUE),
    avg_likes_views_ratio = mean(likes_views_ratio, na.rm = TRUE),
    avg_dislikes_views_ratio = mean(dislikes_views_ratio, na.rm = TRUE),
    .groups = 'drop'
  )

View(mean_ratios_by_country_keyword)
# colnames(aggregated_youtube_data_final)
```
<br>